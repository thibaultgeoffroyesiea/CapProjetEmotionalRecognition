{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18,googlenet, densenet121,mobilenet_v3_small,mobilenet_v3_large\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train head:  ['database_train/06_081.jpg', 'database_train/07_222.jpg', 'database_train/06_209.jpg', 'database_train/03_073.jpg', 'database_train/07_160.jpg'] \n",
      " [5, 6, 5, 2, 6]\n",
      "Test head:  ['database_train/01_206.jpg', 'database_train/06_111.jpg', 'database_train/02_190.jpg', 'database_train/01_076.jpg', 'database_train/02_093.jpg'] \n",
      " [0, 5, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def multiple_dir_files_to_df(dirs, label):\n",
    "    df = pd.DataFrame()\n",
    "    for idx,dir in enumerate(dirs):\n",
    "        files = os.listdir(dir)\n",
    "        files = [dir + '/' + file for file in files]\n",
    "        df = pd.concat([df,pd.DataFrame({'file': files, 'label': label[idx]})])\n",
    "    return df\n",
    "\n",
    "df_au = pd.read_csv(f\"../AU_models/dataset/Database.csv\")\n",
    "\n",
    "labels=[\"neutral\",\"happy\",\"sad\",\"fear\",\"angry\",\"surprise\",\"disgust\"]\n",
    "full_labels =[\"neutral\",\"happy\",\"sad\",\"fear\",\"angry\",\"surprise\",\"disgust\",\"Happily_Surprised\",\n",
    "\"Happily_Disgusted\",\"Sadly_Fearful\",\"Sadly_Angry\",\"Sadly_Surprised\",\"Sadly_Disgusted\",\n",
    "\"Fearfully_Angry\",\"Fearfully_Surprised\",\"Fearfully_Disgusted\",\"Angrily_Surprised\",\n",
    "\"Angrily_Disgusted\",\"Disgustedly_Surprised\",\"Appalled\",\"Hatred\",\"Awed\"]\n",
    "\n",
    "# database=[common_path+label for label in labels]\n",
    "# database_full=[common_path+label for label in full_labels]\n",
    "\n",
    "def training_test_model(train_loader, val_loader, test_loader, model,model_name,epochs=50, learning_rate=0.001,weight_decay=1e-4,gamma=0.9,early_stopping_patience=5,early_stopping_save=True):\n",
    "    # Initialiser le modèle et le journal\n",
    "    model = model\n",
    "    patience = early_stopping_patience\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    accuracy_val_list=[]\n",
    "    accuracy_train_list=[]\n",
    "    loss_val_list=[]\n",
    "    loss_train_list=[]\n",
    "    \n",
    "    # Entraîner le modèle\n",
    "    num_epochs = epochs\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Device: \",device)\n",
    "    model.to(device)\n",
    "\n",
    "    # Définir l'optimiseur et la fonction de perte\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate,weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer,gamma=gamma)\n",
    "    # Entraîner le modèle\n",
    "    for epoch in range(num_epochs):\n",
    "        accuracy_train=[]\n",
    "        loss_train=[]\n",
    "        accuracy_val=[]\n",
    "        loss_val=[]\n",
    "        accuracy_test=[]\n",
    "        loss_test=[]\n",
    "        current_lr = [param_group['lr'] for param_group in optimizer.param_groups][0]\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, (data, targets, _) in enumerate(train_loader):\n",
    "            # Get data to cuda if possible\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            # forward\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets.long())\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            likelihood, predictions = scores.max(1)\n",
    "            loss_train.append(loss.item())\n",
    "            accuracy_train.append((predictions == targets).float().mean().item())\n",
    "\n",
    "            # gradient descent or adam step\n",
    "        scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        for batch_idx, (data, targets, _) in enumerate(val_loader):\n",
    "            # Get data to cuda if possible\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            # forward\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets.long())\n",
    "            \n",
    "            likelihood, predictions = scores.max(1)\n",
    "            loss_val.append(loss.item())\n",
    "            accuracy_val.append((predictions == targets).float().mean().item())\n",
    "\n",
    "        #testing the model\n",
    "        for batch_idx, (data, targets, _)  in enumerate(test_loader):\n",
    "            # Get data to cuda if possible\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            # forward\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets.long())\n",
    "            \n",
    "            likelihood, predictions = scores.max(1)\n",
    "            loss_test.append(loss.item())\n",
    "            accuracy_test.append((predictions == targets).float().mean().item())\n",
    "\n",
    "        accuracy_train=np.array(accuracy_train).mean()\n",
    "        loss_train=np.array(loss_train).mean()\n",
    "        accuracy_val=np.array(accuracy_val).mean()\n",
    "        loss_val=np.array(loss_val).mean()\n",
    "        accuracy_test=np.array(accuracy_test).mean()\n",
    "        loss_test=np.array(loss_test).mean()\n",
    "        accuracy_val_list.append(accuracy_val)\n",
    "        accuracy_train_list.append(accuracy_train)\n",
    "        loss_val_list.append(loss_val)\n",
    "        loss_train_list.append(loss_train)\n",
    "        if loss_val < best_val_loss:\n",
    "                best_val_loss = loss_val\n",
    "                best_val_accuracy = accuracy_val\n",
    "                counter = 0\n",
    "                best_params = model.state_dict()\n",
    "                best_test_accuracy = accuracy_test\n",
    "                best_val_accuracy = accuracy_val\n",
    "        if early_stopping_save:\n",
    "            if loss_val < best_val_loss:\n",
    "                best_val_loss = loss_val\n",
    "                best_val_accuracy = accuracy_val\n",
    "                counter = 0\n",
    "                best_params = model.state_dict()\n",
    "            else:\n",
    "                counter += 1\n",
    "            if counter > patience:\n",
    "                print(\"Early stopping at epoch: \",epoch)\n",
    "                print(\"Saving model...\")\n",
    "                saved_params = model.state_dict()\n",
    "                # get percentage of accuracy\n",
    "                best_val_accuracy = np.round(best_val_accuracy*100,0)\n",
    "                torch.save(saved_params, f\"./models_tg/{model_name}_{str(int(best_val_accuracy))}.pth\")\n",
    "                return accuracy_val_list,accuracy_train_list,loss_val_list,loss_train_list\n",
    "        print(f\"Train epoch: {epoch}, accuracy = {accuracy_train} ,loss = {loss_train}, lr = {np.round(current_lr,6)}\")\n",
    "        print(f\"val epoch: {epoch}, accuracy = {accuracy_val} ,loss = {loss_val}\")\n",
    "        print(f\"test epoch: {epoch}, accuracy = {accuracy_test} ,loss = {loss_test}\")\n",
    "\n",
    "    torch.save(model.state_dict(), rf\"./models_tg/{model_name}_{str(int(accuracy_val))}_{str(int(accuracy_test))}.pth\")\n",
    "\n",
    "\n",
    "    return accuracy_val_list,accuracy_train_list,loss_val_list,loss_train_list\n",
    "\n",
    "def plot_train_loss(accuracy_test_list,accuracy_train_list,loss_test_list,loss_train_list,model_name):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(accuracy_test_list,label=\"accuracy_test\")\n",
    "    plt.plot(accuracy_train_list,label=\"accuracy_train\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy for \"+model_name+\" model\")\n",
    "    plt.legend()\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(loss_test_list,label=\"loss_test\")\n",
    "    plt.plot(loss_train_list,label=\"loss_train\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss for \"+model_name+\" model\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "# df = multiple_dir_files_to_df(database,np.linspace(0,6,7))\n",
    "# X,y=df[\"file\"].tolist(),df[\"label\"].tolist()\n",
    "\n",
    "# #Split the dataset into train and test\n",
    "# df_full = multiple_dir_files_to_df(database_full,np.linspace(0,21,22))\n",
    "\n",
    "df_full = pd.read_csv(f\"database_train.csv\")\n",
    "\n",
    "\n",
    "X_full= [\"database_train/\" + s for s in df_full[\"filenames\"].values]\n",
    "y_full= [int(i.split(\"_\")[0]) -1 for i in df_full[\"filenames\"].values]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#get data with labels\n",
    "X_train = [X_full[i] for i in range(len(X_full)) if int(y_full[i]) < 7]\n",
    "y_train = [y_full[i] for i in range(len(y_full)) if int(y_full[i]) < 7]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "print(\"Train head: \",X_train[:5],\"\\n\",y_train[:5])\n",
    "print(\"Test head: \",X_val[:5],\"\\n\",y_val[:5])\n",
    "\n",
    "# Définir un Dataset personnalisé\n",
    "# Définir un Dataset personnalisé\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_names, labels,  transform=None):\n",
    "        self.file_names = file_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = f'{self.file_names[idx]}' \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image, label = image.to(device), label.to(device)\n",
    "\n",
    "        return image, label, self.file_names[idx]\n",
    "\n",
    "# Define the image transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "# Créer les jeux de données et les chargeurs de données\n",
    "train_dataset = CustomDataset(X_train, y_train, transform=train_transform)\n",
    "val_dataset = CustomDataset(X_val, y_val, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mobilenet = mobilenet_v3_small(weights='IMAGENET1K_V1')\n",
    "        self.mobilenet.classifier[3] = nn.Linear(1024, 7)\n",
    "    def forward(self, x):\n",
    "        return self.mobilenet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f\"database_test.csv\")\n",
    "\n",
    "\n",
    "X_test_full= [\"database_test/\" + s for s in df_test[\"filenames\"].values]\n",
    "y_test_full= [int(i.split(\"_\")[0]) -1 for i in df_test[\"filenames\"].values]\n",
    "\n",
    "\n",
    "\n",
    "#get data with labels\n",
    "X_test = [X_test_full[i] for i in range(len(X_test_full)) if int(y_test_full[i]) < 7]\n",
    "y_test = [y_test_full[i] for i in range(len(y_test_full)) if int(y_test_full[i]) < 7]\n",
    "\n",
    "test_loader = DataLoader(CustomDataset(X_test, y_test, transform=test_transform), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "Train epoch: 0, accuracy = 0.45886536770396763 ,loss = 1.3513596802949905, lr = 0.001\n",
      "val epoch: 0, accuracy = 0.3472222222222222 ,loss = 2.232545084423489\n",
      "test epoch: 0, accuracy = 0.29545454680919647 ,loss = 2.3814975221951804\n",
      "Train epoch: 1, accuracy = 0.7113855282465616 ,loss = 0.7413101295630137, lr = 0.0009\n",
      "val epoch: 1, accuracy = 0.2743055555555556 ,loss = 3.1139051384396024\n",
      "test epoch: 1, accuracy = 0.264678031206131 ,loss = 2.4884703954060874\n",
      "Train epoch: 2, accuracy = 0.804491486814287 ,loss = 0.5271010891430907, lr = 0.00081\n",
      "val epoch: 2, accuracy = 0.5 ,loss = 2.5700203312767878\n",
      "test epoch: 2, accuracy = 0.5492424269517263 ,loss = 2.3116746743520102\n",
      "Train epoch: 3, accuracy = 0.8410618272092607 ,loss = 0.4124825182888243, lr = 0.000729\n",
      "val epoch: 3, accuracy = 0.5590277777777778 ,loss = 1.4666970835791693\n",
      "test epoch: 3, accuracy = 0.5539772709210714 ,loss = 1.3985259930292766\n",
      "Train epoch: 4, accuracy = 0.8661514321962992 ,loss = 0.35563602132929695, lr = 0.000656\n",
      "val epoch: 4, accuracy = 0.5104166666666666 ,loss = 1.6299480729632907\n",
      "test epoch: 4, accuracy = 0.5028409113486608 ,loss = 1.732296069463094\n",
      "Train epoch: 5, accuracy = 0.9165266570117738 ,loss = 0.2527857246912188, lr = 0.00059\n",
      "val epoch: 5, accuracy = 0.5486111111111112 ,loss = 1.3808135853873358\n",
      "test epoch: 5, accuracy = 0.6477272709210714 ,loss = 1.1753334999084473\n",
      "Train epoch: 6, accuracy = 0.9096662170357175 ,loss = 0.2557864265723361, lr = 0.000531\n",
      "val epoch: 6, accuracy = 0.53125 ,loss = 1.3723465998967488\n",
      "test epoch: 6, accuracy = 0.5189393957455953 ,loss = 1.3247991402943928\n",
      "Train epoch: 7, accuracy = 0.9061099903451072 ,loss = 0.24111500196158886, lr = 0.000478\n",
      "val epoch: 7, accuracy = 0.6041666666666666 ,loss = 0.9899943802091811\n",
      "test epoch: 7, accuracy = 0.6946022709210714 ,loss = 0.872534861167272\n",
      "Train epoch: 8, accuracy = 0.9235551059246063 ,loss = 0.22237562139829, lr = 0.00043\n",
      "val epoch: 8, accuracy = 0.7291666666666666 ,loss = 0.7630158828364478\n",
      "test epoch: 8, accuracy = 0.7665719787279764 ,loss = 0.683550496896108\n",
      "Train epoch: 9, accuracy = 0.9365759392579397 ,loss = 0.15655791790535054, lr = 0.000387\n",
      "val epoch: 9, accuracy = 0.7777777777777778 ,loss = 0.7381194531917572\n",
      "test epoch: 9, accuracy = 0.7722537914911906 ,loss = 0.6401702761650085\n",
      "Train epoch: 10, accuracy = 0.9548331085178587 ,loss = 0.13411388153003323, lr = 0.000349\n",
      "val epoch: 10, accuracy = 0.75 ,loss = 0.7881402042176988\n",
      "test epoch: 10, accuracy = 0.8025568226973215 ,loss = 0.6623889058828354\n",
      "Train epoch: 11, accuracy = 0.9375 ,loss = 0.17094084630823797, lr = 0.000314\n",
      "val epoch: 11, accuracy = 0.78125 ,loss = 0.7030852105882432\n",
      "test epoch: 11, accuracy = 0.8186553120613098 ,loss = 0.5111716464161873\n",
      "Train epoch: 12, accuracy = 0.9548051059246063 ,loss = 0.12245252066188389, lr = 0.000282\n",
      "val epoch: 12, accuracy = 0.8194444444444444 ,loss = 0.6476660304599338\n",
      "test epoch: 12, accuracy = 0.8494318226973215 ,loss = 0.5287580738464991\n",
      "Train epoch: 13, accuracy = 0.9730902777777778 ,loss = 0.0885832706052396, lr = 0.000254\n",
      "val epoch: 13, accuracy = 0.7951388888888888 ,loss = 0.6982846260070801\n",
      "test epoch: 13, accuracy = 0.8233901560306549 ,loss = 0.5640419448415438\n",
      "Train epoch: 14, accuracy = 0.9539370503690507 ,loss = 0.1117924759681854, lr = 0.000229\n",
      "val epoch: 14, accuracy = 0.8020833333333334 ,loss = 0.6829375624656677\n",
      "test epoch: 14, accuracy = 0.8030303120613098 ,loss = 0.6021945675214132\n",
      "Train epoch: 15, accuracy = 0.96875 ,loss = 0.08824773642441465, lr = 0.000206\n",
      "val epoch: 15, accuracy = 0.8159722222222222 ,loss = 0.7318850921259986\n",
      "test epoch: 15, accuracy = 0.8233901560306549 ,loss = 0.5645474394162496\n",
      "Train epoch: 16, accuracy = 0.9695620503690507 ,loss = 0.09325236889223258, lr = 0.000185\n",
      "val epoch: 16, accuracy = 0.8125 ,loss = 0.738571564356486\n",
      "test epoch: 16, accuracy = 0.8390151560306549 ,loss = 0.5461568981409073\n",
      "Train epoch: 17, accuracy = 0.9721662170357175 ,loss = 0.0753668585869794, lr = 0.000167\n",
      "val epoch: 17, accuracy = 0.8368055555555556 ,loss = 0.6646994683477614\n",
      "test epoch: 17, accuracy = 0.8338068226973215 ,loss = 0.5652086113890012\n",
      "Train epoch: 18, accuracy = 0.9730622751845254 ,loss = 0.08396221635242303, lr = 0.00015\n",
      "val epoch: 18, accuracy = 0.8298611111111112 ,loss = 0.7569867372512817\n",
      "test epoch: 18, accuracy = 0.8442234893639883 ,loss = 0.6385855153203011\n",
      "Train epoch: 19, accuracy = 0.9782706085178587 ,loss = 0.06003313615090317, lr = 0.000135\n",
      "val epoch: 19, accuracy = 0.8506944444444444 ,loss = 0.7132371531592475\n",
      "test epoch: 19, accuracy = 0.8494318226973215 ,loss = 0.5856247618794441\n",
      "Train epoch: 20, accuracy = 0.9800067196289698 ,loss = 0.05354986044888695, lr = 0.000122\n",
      "val epoch: 20, accuracy = 0.8506944444444444 ,loss = 0.6234195629755656\n",
      "test epoch: 20, accuracy = 0.8494318226973215 ,loss = 0.57279834151268\n",
      "Train epoch: 21, accuracy = 0.9800067196289698 ,loss = 0.05447169297581746, lr = 0.000109\n",
      "val epoch: 21, accuracy = 0.8229166666666666 ,loss = 0.7283030384116702\n",
      "test epoch: 21, accuracy = 0.8390151560306549 ,loss = 0.531412199139595\n",
      "Train epoch: 22, accuracy = 0.9852430555555556 ,loss = 0.05774084098326663, lr = 9.8e-05\n",
      "val epoch: 22, accuracy = 0.8298611111111112 ,loss = 0.699578089846505\n",
      "test epoch: 22, accuracy = 0.8546401560306549 ,loss = 0.5439474682013193\n",
      "Train epoch: 23, accuracy = 0.9826388888888888 ,loss = 0.04944507635405494, lr = 8.9e-05\n",
      "val epoch: 23, accuracy = 0.8506944444444444 ,loss = 0.6178665492269728\n",
      "test epoch: 23, accuracy = 0.8442234893639883 ,loss = 0.5393934547901154\n",
      "Train epoch: 24, accuracy = 0.9834509392579397 ,loss = 0.055498414220184915, lr = 8e-05\n",
      "val epoch: 24, accuracy = 0.8472222222222222 ,loss = 0.6664115753438737\n",
      "test epoch: 24, accuracy = 0.8442234893639883 ,loss = 0.5528204838434855\n",
      "Train epoch: 25, accuracy = 0.9878472222222222 ,loss = 0.03993728006025776, lr = 7.2e-05\n",
      "val epoch: 25, accuracy = 0.8472222222222222 ,loss = 0.666664825545417\n",
      "test epoch: 25, accuracy = 0.8494318226973215 ,loss = 0.58749886850516\n",
      "Train epoch: 26, accuracy = 0.9860831085178587 ,loss = 0.04396119465430578, lr = 6.5e-05\n",
      "val epoch: 26, accuracy = 0.8402777777777778 ,loss = 0.699932701057858\n",
      "test epoch: 26, accuracy = 0.8546401560306549 ,loss = 0.5577433258295059\n",
      "Train epoch: 27, accuracy = 0.9859991040494707 ,loss = 0.041393490640782855, lr = 5.8e-05\n",
      "val epoch: 27, accuracy = 0.8611111111111112 ,loss = 0.6472467382748922\n",
      "test epoch: 27, accuracy = 0.8494318226973215 ,loss = 0.5611294582486153\n",
      "Train epoch: 28, accuracy = 0.9895833333333334 ,loss = 0.03836629314658543, lr = 5.2e-05\n",
      "val epoch: 28, accuracy = 0.8541666666666666 ,loss = 0.7631058063771989\n",
      "test epoch: 28, accuracy = 0.8442234893639883 ,loss = 0.5937748004992803\n",
      "Train epoch: 29, accuracy = 0.9878472222222222 ,loss = 0.034845537409031145, lr = 4.7e-05\n",
      "val epoch: 29, accuracy = 0.8402777777777778 ,loss = 0.6594124171468947\n",
      "test epoch: 29, accuracy = 0.8442234893639883 ,loss = 0.628399113814036\n",
      "Train epoch: 30, accuracy = 0.9895833333333334 ,loss = 0.03571940379010306, lr = 4.2e-05\n",
      "val epoch: 30, accuracy = 0.8541666666666666 ,loss = 0.6929947071605258\n",
      "test epoch: 30, accuracy = 0.8546401560306549 ,loss = 0.6059020857016245\n",
      "Train epoch: 31, accuracy = 0.9861111111111112 ,loss = 0.04376833621386646, lr = 3.8e-05\n",
      "val epoch: 31, accuracy = 0.84375 ,loss = 0.6694736232360204\n",
      "test epoch: 31, accuracy = 0.8546401560306549 ,loss = 0.596249816318353\n",
      "Train epoch: 32, accuracy = 0.9869791666666666 ,loss = 0.035690403595152825, lr = 3.4e-05\n",
      "val epoch: 32, accuracy = 0.8368055555555556 ,loss = 0.68267293771108\n",
      "test epoch: 32, accuracy = 0.8390151560306549 ,loss = 0.6184532965222994\n",
      "Train epoch: 33, accuracy = 0.9904513888888888 ,loss = 0.035136083089229136, lr = 3.1e-05\n",
      "val epoch: 33, accuracy = 0.8298611111111112 ,loss = 0.6742956538995107\n",
      "test epoch: 33, accuracy = 0.8442234893639883 ,loss = 0.6142855087916056\n",
      "Train epoch: 34, accuracy = 0.9904513888888888 ,loss = 0.032424796185094036, lr = 2.8e-05\n",
      "val epoch: 34, accuracy = 0.8472222222222222 ,loss = 0.6809684750106599\n",
      "test epoch: 34, accuracy = 0.8442234893639883 ,loss = 0.6083593765894572\n",
      "Train epoch: 35, accuracy = 0.9904513888888888 ,loss = 0.02423956826290426, lr = 2.5e-05\n",
      "val epoch: 35, accuracy = 0.8333333333333334 ,loss = 0.662745381395022\n",
      "test epoch: 35, accuracy = 0.8494318226973215 ,loss = 0.6257713735103607\n",
      "Train epoch: 36, accuracy = 0.9921875 ,loss = 0.02948622634479155, lr = 2.3e-05\n",
      "val epoch: 36, accuracy = 0.8506944444444444 ,loss = 0.6915603710545434\n",
      "test epoch: 36, accuracy = 0.8494318226973215 ,loss = 0.6191474944353104\n",
      "Train epoch: 37, accuracy = 0.984375 ,loss = 0.04509643491150604, lr = 2e-05\n",
      "val epoch: 37, accuracy = 0.8402777777777778 ,loss = 0.7629305356078677\n",
      "test epoch: 37, accuracy = 0.8494318226973215 ,loss = 0.6253255779544512\n",
      "Train epoch: 38, accuracy = 0.9913194444444444 ,loss = 0.031504341433497354, lr = 1.8e-05\n",
      "val epoch: 38, accuracy = 0.8333333333333334 ,loss = 0.6918725338247087\n",
      "test epoch: 38, accuracy = 0.8442234893639883 ,loss = 0.6179239898920059\n",
      "Train epoch: 39, accuracy = 0.9887152777777778 ,loss = 0.037888987209751375, lr = 1.6e-05\n",
      "val epoch: 39, accuracy = 0.8368055555555556 ,loss = 0.7172552247842153\n",
      "test epoch: 39, accuracy = 0.8390151560306549 ,loss = 0.6249642670154572\n",
      "Train epoch: 40, accuracy = 0.9869791666666666 ,loss = 0.03083573011422737, lr = 1.5e-05\n",
      "val epoch: 40, accuracy = 0.8298611111111112 ,loss = 0.7994457085927328\n",
      "test epoch: 40, accuracy = 0.8442234893639883 ,loss = 0.6122496202588081\n",
      "Train epoch: 41, accuracy = 0.9921594974067476 ,loss = 0.02838580298703164, lr = 1.3e-05\n",
      "val epoch: 41, accuracy = 0.8402777777777778 ,loss = 0.7192116479078928\n",
      "test epoch: 41, accuracy = 0.8442234893639883 ,loss = 0.6171942378083864\n",
      "Train epoch: 42, accuracy = 0.9904513888888888 ,loss = 0.029871526982687, lr = 1.2e-05\n",
      "val epoch: 42, accuracy = 0.8506944444444444 ,loss = 0.7101044091913435\n",
      "test epoch: 42, accuracy = 0.8442234893639883 ,loss = 0.6174216816822687\n",
      "Train epoch: 43, accuracy = 0.9913194444444444 ,loss = 0.03428335677340834, lr = 1.1e-05\n",
      "val epoch: 43, accuracy = 0.8541666666666666 ,loss = 0.7178280651569366\n",
      "test epoch: 43, accuracy = 0.8494318226973215 ,loss = 0.6298664609591166\n",
      "Train epoch: 44, accuracy = 0.9921875 ,loss = 0.024475440628723137, lr = 1e-05\n",
      "val epoch: 44, accuracy = 0.8576388888888888 ,loss = 0.7191597852442\n",
      "test epoch: 44, accuracy = 0.8494318226973215 ,loss = 0.6347251882155737\n",
      "Train epoch: 45, accuracy = 0.9930555555555556 ,loss = 0.0337554945015452, lr = 9e-06\n",
      "val epoch: 45, accuracy = 0.8333333333333334 ,loss = 0.7303705745273166\n",
      "test epoch: 45, accuracy = 0.8494318226973215 ,loss = 0.6294162223736445\n",
      "Train epoch: 46, accuracy = 0.9921875 ,loss = 0.026814700534386147, lr = 8e-06\n",
      "val epoch: 46, accuracy = 0.8472222222222222 ,loss = 0.667961609032419\n",
      "test epoch: 46, accuracy = 0.8442234893639883 ,loss = 0.6322415620088577\n",
      "Train epoch: 47, accuracy = 0.9887152777777778 ,loss = 0.0373639605111546, lr = 7e-06\n",
      "val epoch: 47, accuracy = 0.8541666666666666 ,loss = 0.7650908331076304\n",
      "test epoch: 47, accuracy = 0.8442234893639883 ,loss = 0.6320274074872335\n",
      "Train epoch: 48, accuracy = 0.9921875 ,loss = 0.026601525689733937, lr = 6e-06\n",
      "val epoch: 48, accuracy = 0.8576388888888888 ,loss = 0.6906991336080763\n",
      "test epoch: 48, accuracy = 0.8442234893639883 ,loss = 0.634300043185552\n",
      "Train epoch: 49, accuracy = 0.9904233862956365 ,loss = 0.02988094964530319, lr = 6e-06\n",
      "val epoch: 49, accuracy = 0.8506944444444444 ,loss = 0.7781187759505378\n",
      "test epoch: 49, accuracy = 0.8442234893639883 ,loss = 0.6346231053272883\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m=\u001b[39mMobileNet()\n\u001b[1;32m----> 2\u001b[0m accuracy_val_list,accuracy_train_list,loss_val_list,loss_train_list\u001b[38;5;241m=\u001b[39mtraining_test_model(train_loader,val_loader, test_loader,model,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMobileNet\u001b[39m\u001b[38;5;124m\"\u001b[39m,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m,gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m,early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,early_stopping_save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m plot_train_loss(accuracy_val_list,accuracy_train_list,loss_val_list,loss_train_list,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMobile_Net\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 161\u001b[0m, in \u001b[0;36mtraining_test_model\u001b[1;34m(train_loader, val_loader, test_loader, model, model_name, epochs, learning_rate, weight_decay, gamma, early_stopping_patience, early_stopping_save)\u001b[0m\n\u001b[0;32m    158\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(scores, targets\u001b[38;5;241m.\u001b[39mlong())\n\u001b[0;32m    160\u001b[0m likelihood, predictions \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 161\u001b[0m loss_val\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    162\u001b[0m accuracy_val\u001b[38;5;241m.\u001b[39mappend((predictions \u001b[38;5;241m==\u001b[39m targets)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m#testing the model\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "model=MobileNet()\n",
    "accuracy_val_list,accuracy_train_list,loss_val_list,loss_train_list=training_test_model(train_loader,val_loader, test_loader,model,\"MobileNet\",epochs=50, learning_rate=0.001,weight_decay=1e-4,gamma=0.9,early_stopping_patience=5,early_stopping_save=False)\n",
    "plot_train_loss(accuracy_val_list,accuracy_train_list,loss_val_list,loss_train_list,\"Mobile_Net\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer les jeux de données et les chargeurs de données\n",
    "t_dataset = CustomDataset(X_test_full, y_test_full, test_transform)\n",
    "t_loader = DataLoader(t_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Extractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mobilenet = mobilenet_v3_small(weights='IMAGENET1K_V1')\n",
    "        self.mobilenet.classifier = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mobilenet(x)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 576)\n",
      "(20, 576)\n",
      "(30, 576)\n",
      "(40, 576)\n",
      "(50, 576)\n",
      "(60, 576)\n",
      "(70, 576)\n",
      "(80, 576)\n",
      "(90, 576)\n",
      "(100, 576)\n",
      "(110, 576)\n",
      "(120, 576)\n",
      "(130, 576)\n",
      "(140, 576)\n",
      "(150, 576)\n",
      "(160, 576)\n",
      "(170, 576)\n",
      "(180, 576)\n",
      "(190, 576)\n",
      "(200, 576)\n",
      "(210, 576)\n",
      "(220, 576)\n",
      "(230, 576)\n",
      "(240, 576)\n",
      "(250, 576)\n",
      "(260, 576)\n",
      "(270, 576)\n",
      "(280, 576)\n",
      "(290, 576)\n",
      "(300, 576)\n",
      "(310, 576)\n",
      "(320, 576)\n",
      "(330, 576)\n",
      "(340, 576)\n",
      "(350, 576)\n",
      "(360, 576)\n",
      "(370, 576)\n",
      "(380, 576)\n",
      "(390, 576)\n",
      "(400, 576)\n",
      "(410, 576)\n",
      "(420, 576)\n",
      "(430, 576)\n",
      "(440, 576)\n",
      "(450, 576)\n",
      "(460, 576)\n",
      "(470, 576)\n",
      "(480, 576)\n",
      "(490, 576)\n",
      "(500, 576)\n",
      "(506, 576)\n"
     ]
    }
   ],
   "source": [
    "pretrained_model =rf\"models_tg/MobileNet_88.pth\"\n",
    "model = Feature_Extractor()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location=device), strict=False)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "df=pd.DataFrame()\n",
    "\n",
    "for i, (x, y) in enumerate(t_loader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(x)\n",
    "        df=pd.concat([df,pd.DataFrame(output.cpu().numpy())])\n",
    "        print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_df = pd.read_csv(\"../AU_models/dataset/partial_database.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_df[\"filename\"] = X_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_test = au_df[au_df[\"filename\"].isin(X_test_full)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)\n",
    "dataset = df\n",
    "#normalize data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = MinMaxScaler((0,1))\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "dataset.iloc[:,:] = scaler.fit_transform(dataset.iloc[:,:])\n",
    "dataset = pd.concat([dataset,au_test],axis=1)\n",
    "dataset.reset_index(inplace=True, drop=True)\n",
    "dataset[\"labels\"]=[int(x.split(\"/\")[-1].split(\"_\")[0]) for x in dataset[\"filename\"]]\n",
    "dataset[\"filename\"]=X_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AU01_r</th>\n",
       "      <th>AU02_r</th>\n",
       "      <th>AU04_r</th>\n",
       "      <th>AU05_r</th>\n",
       "      <th>AU06_r</th>\n",
       "      <th>AU07_r</th>\n",
       "      <th>AU09_r</th>\n",
       "      <th>AU10_r</th>\n",
       "      <th>AU12_r</th>\n",
       "      <th>AU14_r</th>\n",
       "      <th>AU15_r</th>\n",
       "      <th>AU17_r</th>\n",
       "      <th>AU20_r</th>\n",
       "      <th>AU23_r</th>\n",
       "      <th>AU25_r</th>\n",
       "      <th>AU26_r</th>\n",
       "      <th>AU45_r</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.39</td>\n",
       "      <td>Image/neutral/01_009.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.18</td>\n",
       "      <td>Image/neutral/01_013.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.37</td>\n",
       "      <td>Image/neutral/01_024.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.08</td>\n",
       "      <td>Image/neutral/01_027.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.40</td>\n",
       "      <td>Image/neutral/01_030.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Image/Awed/22_149.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>1.22</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Image/Awed/22_173.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>1.10</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Image/Awed/22_197.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1.80</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Image/Awed/22_219.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>1.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Image/Awed/22_227.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AU01_r   AU02_r   AU04_r   AU05_r   AU06_r   AU07_r   AU09_r   AU10_r  \\\n",
       "0       0.09     0.00     0.55     0.00     0.00     0.00     0.00     0.23   \n",
       "1       0.73     0.49     0.25     0.00     0.36     0.00     0.00     0.22   \n",
       "2       0.00     0.00     0.73     0.00     0.46     0.04     0.00     0.40   \n",
       "3       0.00     0.02     0.66     0.00     0.15     0.04     0.54     0.05   \n",
       "4       0.52     0.22     0.34     0.04     0.12     0.05     0.00     0.36   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "501     0.80     0.41     0.27     0.24     0.00     0.14     0.00     0.29   \n",
       "502     1.22     0.35     0.90     0.00     0.71     1.10     0.00     0.83   \n",
       "503     1.10     0.87     0.79     0.69     0.00     0.36     0.00     0.65   \n",
       "504     1.80     0.47     0.60     0.78     0.08     0.70     0.00     0.47   \n",
       "505     1.47     0.00     1.05     0.20     0.09     0.38     0.00     0.84   \n",
       "\n",
       "      AU12_r   AU14_r   AU15_r   AU17_r   AU20_r   AU23_r   AU25_r   AU26_r  \\\n",
       "0       0.00     0.00     0.26     0.49     0.00     0.00     0.00     0.26   \n",
       "1       0.47     0.21     0.00     0.44     0.18     0.55     0.20     0.61   \n",
       "2       0.39     1.08     0.63     0.56     0.43     0.73     0.01     0.35   \n",
       "3       0.08     0.12     0.80     1.46     0.34     0.29     0.00     0.18   \n",
       "4       0.23     0.02     0.72     1.71     0.39     0.55     0.00     0.85   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "501     0.00     0.00     0.16     0.47     0.00     0.00     1.99     2.80   \n",
       "502     0.93     0.14     0.13     1.29     0.02     0.00     1.18     2.96   \n",
       "503     0.19     0.00     0.45     1.13     0.06     0.09     2.13     2.89   \n",
       "504     0.41     0.00     0.16     0.94     0.00     0.00     1.89     2.52   \n",
       "505     0.49     0.05     0.34     0.23     0.13     0.33     1.87     1.92   \n",
       "\n",
       "      AU45_r                  filename  \n",
       "0       0.39  Image/neutral/01_009.jpg  \n",
       "1       0.18  Image/neutral/01_013.jpg  \n",
       "2       0.37  Image/neutral/01_024.jpg  \n",
       "3       0.08  Image/neutral/01_027.jpg  \n",
       "4       0.40  Image/neutral/01_030.jpg  \n",
       "..       ...                       ...  \n",
       "501     0.22     Image/Awed/22_149.jpg  \n",
       "502     0.00     Image/Awed/22_173.jpg  \n",
       "503     0.21     Image/Awed/22_197.jpg  \n",
       "504     0.00     Image/Awed/22_219.jpg  \n",
       "505     0.00     Image/Awed/22_227.jpg  \n",
       "\n",
       "[506 rows x 18 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"testing_database\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = y_test\n",
    "df [\"filename\"] = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_transform = transforms.Compose([\n",
    "    # transforms.CenterCrop((800, 800)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(au_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tibot\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\tibot\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tibot\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m train_full_dataset \u001b[38;5;241m=\u001b[39m CustomDataset(X_train_full, y_train_full, au_train_full, transform\u001b[38;5;241m=\u001b[39maug_transform)\n\u001b[0;32m      2\u001b[0m train_full_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_full_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y, au) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_full_loader):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape, y\u001b[38;5;241m.\u001b[39mshape, au\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# plt.imshow(x[0].permute(1, 2, 0))\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[1], line 217\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    214\u001b[0m image, label \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mto(device), label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mau \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 217\u001b[0m     au \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mau[idx]\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image, label, au\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n",
      "File \u001b[1;32mc:\\Users\\tibot\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\tibot\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "\n",
    "train_full_dataset = CustomDataset(X_train_full, y_train_full, au_train_full, transform=aug_transform)\n",
    "train_full_loader = DataLoader(train_full_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "for i, (x, y, au) in enumerate(train_full_loader):\n",
    "    print(x.shape, y.shape, au.shape)\n",
    "    # plt.imshow(x[0].permute(1, 2, 0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_loader = DataLoader(CustomDataset(X, y, aug_transform), batch_size=31, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(f\"../AU_models/dataset/Database.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>face_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>confidence</th>\n",
       "      <th>success</th>\n",
       "      <th>gaze_0_x</th>\n",
       "      <th>gaze_0_y</th>\n",
       "      <th>gaze_0_z</th>\n",
       "      <th>gaze_1_x</th>\n",
       "      <th>gaze_1_y</th>\n",
       "      <th>...</th>\n",
       "      <th>AU12_c</th>\n",
       "      <th>AU14_c</th>\n",
       "      <th>AU15_c</th>\n",
       "      <th>AU17_c</th>\n",
       "      <th>AU20_c</th>\n",
       "      <th>AU23_c</th>\n",
       "      <th>AU25_c</th>\n",
       "      <th>AU26_c</th>\n",
       "      <th>AU28_c</th>\n",
       "      <th>AU45_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120585</td>\n",
       "      <td>0.015412</td>\n",
       "      <td>-0.992583</td>\n",
       "      <td>-0.132393</td>\n",
       "      <td>0.050480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.042829</td>\n",
       "      <td>0.085608</td>\n",
       "      <td>-0.995408</td>\n",
       "      <td>-0.098998</td>\n",
       "      <td>0.062438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.137724</td>\n",
       "      <td>0.030648</td>\n",
       "      <td>-0.989996</td>\n",
       "      <td>-0.020681</td>\n",
       "      <td>0.038882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0.092643</td>\n",
       "      <td>0.302859</td>\n",
       "      <td>-0.948522</td>\n",
       "      <td>-0.123163</td>\n",
       "      <td>0.099764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034448</td>\n",
       "      <td>-0.012279</td>\n",
       "      <td>-0.999331</td>\n",
       "      <td>-0.155066</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5055</th>\n",
       "      <td>5056</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.105966</td>\n",
       "      <td>-0.058768</td>\n",
       "      <td>-0.992632</td>\n",
       "      <td>-0.271235</td>\n",
       "      <td>0.051710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056</th>\n",
       "      <td>5057</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.038780</td>\n",
       "      <td>-0.106725</td>\n",
       "      <td>-0.993532</td>\n",
       "      <td>-0.240089</td>\n",
       "      <td>-0.021937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>5058</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.023173</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>-0.999631</td>\n",
       "      <td>-0.131889</td>\n",
       "      <td>0.021436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5058</th>\n",
       "      <td>5059</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007678</td>\n",
       "      <td>-0.052453</td>\n",
       "      <td>-0.998594</td>\n",
       "      <td>-0.115005</td>\n",
       "      <td>-0.005229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5059</th>\n",
       "      <td>5060</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.042327</td>\n",
       "      <td>0.034919</td>\n",
       "      <td>-0.998493</td>\n",
       "      <td>-0.207819</td>\n",
       "      <td>0.067027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5060 rows × 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      frame   face_id   timestamp   confidence   success   gaze_0_x  \\\n",
       "0         1         0         0.0         0.98         1   0.120585   \n",
       "1         2         0         0.0         0.98         1   0.042829   \n",
       "2         3         0         0.0         0.98         1   0.137724   \n",
       "3         4         0         0.0         0.77         1   0.092643   \n",
       "4         5         0         0.0         0.98         1   0.034448   \n",
       "...     ...       ...         ...          ...       ...        ...   \n",
       "5055   5056         0         0.0         0.88         1  -0.105966   \n",
       "5056   5057         0         0.0         0.88         1  -0.038780   \n",
       "5057   5058         0         0.0         0.98         1  -0.023173   \n",
       "5058   5059         0         0.0         0.98         1  -0.007678   \n",
       "5059   5060         0         0.0         0.98         1  -0.042327   \n",
       "\n",
       "       gaze_0_y   gaze_0_z   gaze_1_x   gaze_1_y  ...   AU12_c   AU14_c  \\\n",
       "0      0.015412  -0.992583  -0.132393   0.050480  ...      0.0      0.0   \n",
       "1      0.085608  -0.995408  -0.098998   0.062438  ...      0.0      0.0   \n",
       "2      0.030648  -0.989996  -0.020681   0.038882  ...      0.0      0.0   \n",
       "3      0.302859  -0.948522  -0.123163   0.099764  ...      0.0      0.0   \n",
       "4     -0.012279  -0.999331  -0.155066   0.001050  ...      0.0      0.0   \n",
       "...         ...        ...        ...        ...  ...      ...      ...   \n",
       "5055  -0.058768  -0.992632  -0.271235   0.051710  ...      0.0      0.0   \n",
       "5056  -0.106725  -0.993532  -0.240089  -0.021937  ...      0.0      0.0   \n",
       "5057   0.014200  -0.999631  -0.131889   0.021436  ...      0.0      0.0   \n",
       "5058  -0.052453  -0.998594  -0.115005  -0.005229  ...      0.0      0.0   \n",
       "5059   0.034919  -0.998493  -0.207819   0.067027  ...      0.0      0.0   \n",
       "\n",
       "       AU15_c   AU17_c   AU20_c   AU23_c   AU25_c   AU26_c   AU28_c   AU45_c  \n",
       "0         0.0      0.0      0.0      0.0      0.0      0.0      0.0      1.0  \n",
       "1         0.0      1.0      0.0      0.0      0.0      1.0      0.0      0.0  \n",
       "2         1.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "3         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "4         0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...  \n",
       "5055      0.0      0.0      0.0      0.0      1.0      1.0      0.0      0.0  \n",
       "5056      0.0      0.0      0.0      0.0      1.0      1.0      0.0      0.0  \n",
       "5057      0.0      0.0      1.0      0.0      1.0      1.0      0.0      0.0  \n",
       "5058      0.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0  \n",
       "5059      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  \n",
       "\n",
       "[5060 rows x 714 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "' x_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\tibot\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\tibot\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tibot\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ' x_0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m x_0\u001b[39m\u001b[38;5;124m\"\u001b[39m], df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m y_0\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\tibot\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\tibot\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: ' x_0'"
     ]
    }
   ],
   "source": [
    "df[\" x_0\"], df[\" y_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'Image'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#get first value from t_loader\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (image, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_full_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(image[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\tgeoffroy\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\tgeoffroy\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\tgeoffroy\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\tgeoffroy\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[22], line 205\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    202\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m--> 205\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    208\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tgeoffroy\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\tgeoffroy\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tgeoffroy\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:166\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[0;32m    165\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[1;32m--> 166\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    169\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'Image'"
     ]
    }
   ],
   "source": [
    "#get first value from t_loader\n",
    "\n",
    "for (image, label) in list(enumerate(train_full_loader))[:1]:\n",
    "    plt.imshow(image[0].permute(1, 2, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
